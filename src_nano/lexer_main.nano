/* Backwards-compatible wrapper that exposes tokenize(source) from the lexer lib. */

import "src_nano/compiler/lexer.nano"

fn tokenize(source: string) -> List<LexToken> {
    return (tokenize_string source)
}

shadow tokenize {
    let source1: string = "fn main() -> int { return 0 }"
    let tokens1: List<LexToken> = (tokenize source1)
    assert (> (list_LexToken_length tokens1) 0)
}

fn main() -> int {
    return 0
}

shadow main { assert (== (main) 0) }

