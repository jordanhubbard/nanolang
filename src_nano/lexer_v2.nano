/* =============================================================================
 * nanolang Lexer (Self-Hosted) - Version 2
 * =============================================================================
 * Fixed version that works with current nanolang implementation
 */

/* Token types - simplified names without TOKEN_ prefix */
enum TokenType {
    EOF = 0,
    NUMBER = 1,
    FLOAT = 2,
    STRING = 3,
    IDENTIFIER = 4,
    TRUE = 5,
    FALSE = 6,
    
    /* Delimiters */
    LPAREN = 7,
    RPAREN = 8,
    LBRACE = 9,
    RBRACE = 10,
    LBRACKET = 11,
    RBRACKET = 12,
    COMMA = 13,
    COLON = 14,
    ARROW = 15,
    ASSIGN = 16,
    DOT = 17,
    
    /* Keywords */
    EXTERN = 18,
    FN = 19,
    LET = 20,
    MUT = 21,
    SET = 22,
    IF = 23,
    ELSE = 24,
    WHILE = 25,
    FOR = 26,
    IN = 27,
    RETURN = 28,
    ASSERT = 29,
    SHADOW = 30,
    PRINT = 31,
    ARRAY_KW = 32,
    STRUCT = 33,
    ENUM = 34,
    UNION = 35,
    MATCH = 36,
    
    /* Type keywords */
    TYPE_INT = 37,
    TYPE_FLOAT = 38,
    TYPE_BOOL = 39,
    TYPE_STRING = 40,
    TYPE_VOID = 41,
    
    /* Operators */
    PLUS = 42,
    MINUS = 43,
    STAR = 44,
    SLASH = 45,
    PERCENT = 46,
    EQ = 47,
    NE = 48,
    LT = 49,
    LE = 50,
    GT = 51,
    GE = 52,
    AND_KW = 53,
    OR_KW = 54,
    NOT_KW = 55,
    RANGE = 56
}

/* Token structure */
struct Token {
    token_type: int,
    value: string,
    line: int,
    column: int
}

/* Rename character helpers to avoid builtin conflicts */
fn char_is_digit(c: int) -> bool {
    return (and (>= c 48) (<= c 57))  /* '0' to '9' */
}

shadow char_is_digit {
    assert (== (char_is_digit 48) true)   /* '0' */
    assert (== (char_is_digit 57) true)   /* '9' */
    assert (== (char_is_digit 65) false)  /* 'A' */
}

fn char_is_letter(c: int) -> bool {
    return (or
        (and (>= c 65) (<= c 90))   /* 'A' to 'Z' */
        (and (>= c 97) (<= c 122))) /* 'a' to 'z' */
}

shadow char_is_letter {
    assert (== (char_is_letter 65) true)   /* 'A' */
    assert (== (char_is_letter 90) true)   /* 'Z' */
    assert (== (char_is_letter 97) true)   /* 'a' */
    assert (== (char_is_letter 122) true)  /* 'z' */
    assert (== (char_is_letter 48) false)  /* '0' */
}

fn char_can_start_id(c: int) -> bool {
    return (or (char_is_letter c) (== c 95))  /* letter or '_' */
}

shadow char_can_start_id {
    assert (== (char_can_start_id 65) true)   /* 'A' */
    assert (== (char_can_start_id 95) true)   /* '_' */
    assert (== (char_can_start_id 48) false)  /* '0' */
}

fn char_can_continue_id(c: int) -> bool {
    return (or (char_is_letter c) (or (char_is_digit c) (== c 95)))
}

shadow char_can_continue_id {
    assert (== (char_can_continue_id 65) true)   /* 'A' */
    assert (== (char_can_continue_id 48) true)   /* '0' */
    assert (== (char_can_continue_id 95) true)   /* '_' */
    assert (== (char_can_continue_id 32) false)  /* space */
}

/* String comparison - use builtin str_equals which exists */
fn strings_equal(s1: string, s2: string) -> bool {
    return (str_equals s1 s2)
}

shadow strings_equal {
    assert (== (strings_equal "hello" "hello") true)
    assert (== (strings_equal "hello" "world") false)
}

/* Extract substring */
fn substr(s: string, start: int, length: int) -> string {
    let mut result: string = ""
    let mut i: int = 0
    while (< i length) {
        let c: int = (char_at s (+ start i))
        set result (str_concat result (string_from_char c))
        set i (+ i 1)
    }
    return result
}

shadow substr {
    assert (== (substr "hello" 0 5) "hello")
    assert (== (substr "hello" 1 3) "ell")
    assert (== (substr "hello" 2 2) "ll")
}

/* Keyword classification */
fn classify_keyword(word: string) -> int {
    /* Keywords */
    if (strings_equal word "extern") { return TokenType.EXTERN } else {}
    if (strings_equal word "fn") { return TokenType.FN } else {}
    if (strings_equal word "let") { return TokenType.LET } else {}
    if (strings_equal word "mut") { return TokenType.MUT } else {}
    if (strings_equal word "set") { return TokenType.SET } else {}
    if (strings_equal word "if") { return TokenType.IF } else {}
    if (strings_equal word "else") { return TokenType.ELSE } else {}
    if (strings_equal word "while") { return TokenType.WHILE } else {}
    if (strings_equal word "for") { return TokenType.FOR } else {}
    if (strings_equal word "in") { return TokenType.IN } else {}
    if (strings_equal word "return") { return TokenType.RETURN } else {}
    if (strings_equal word "assert") { return TokenType.ASSERT } else {}
    if (strings_equal word "shadow") { return TokenType.SHADOW } else {}
    if (strings_equal word "print") { return TokenType.PRINT } else {}
    if (strings_equal word "array") { return TokenType.ARRAY_KW } else {}
    if (strings_equal word "struct") { return TokenType.STRUCT } else {}
    if (strings_equal word "enum") { return TokenType.ENUM } else {}
    if (strings_equal word "union") { return TokenType.UNION } else {}
    if (strings_equal word "match") { return TokenType.MATCH } else {}
    
    /* Boolean literals */
    if (strings_equal word "true") { return TokenType.TRUE } else {}
    if (strings_equal word "false") { return TokenType.FALSE } else {}
    
    /* Types */
    if (strings_equal word "int") { return TokenType.TYPE_INT } else {}
    if (strings_equal word "float") { return TokenType.TYPE_FLOAT } else {}
    if (strings_equal word "bool") { return TokenType.TYPE_BOOL } else {}
    if (strings_equal word "string") { return TokenType.TYPE_STRING } else {}
    if (strings_equal word "void") { return TokenType.TYPE_VOID } else {}
    
    /* Operators as keywords */
    if (strings_equal word "and") { return TokenType.AND_KW } else {}
    if (strings_equal word "or") { return TokenType.OR_KW } else {}
    if (strings_equal word "not") { return TokenType.NOT_KW } else {}
    if (strings_equal word "range") { return TokenType.RANGE } else {}
    
    return TokenType.IDENTIFIER
}

shadow classify_keyword {
    assert (== (classify_keyword "fn") 19)  /* TokenType.FN */
    assert (== (classify_keyword "let") 20)  /* TokenType.LET */
    assert (== (classify_keyword "hello") 4)  /* TokenType.IDENTIFIER */
}

/* Create a token */
fn new_token(token_type: int, value: string, line: int, column: int) -> Token {
    return Token {
        token_type: token_type,
        value: value,
        line: line,
        column: column
    }
}

shadow new_token {
    let t: Token = (new_token 1 "42" 1 1)  /* TokenType.NUMBER = 1 */
    assert (== t.token_type 1)  /* TokenType.NUMBER */
    assert (== (str_equals t.value "42") true)
}

/* Main tokenization - returns array of tokens 
 * Note: We build a fixed-size array since we don't have dynamic arrays yet
 */
fn lex(source: string) -> array<Token> {
    let source_len: int = (str_length source)
    
    /* Pre-allocate max possible tokens (every char could be a token in worst case) */
    let mut tokens: array<Token> = []
    let mut token_count: int = 0
    let max_tokens: int = (+ source_len 1)
    
    let mut i: int = 0
    let mut line: int = 1
    let mut line_start: int = 0
    
    /* Main lexing loop */
    while (< i source_len) {
        let c: int = (char_at source i)
        
        /* Skip whitespace */
        if (is_whitespace c) {
            if (== c 10) {  /* newline */
                set line (+ line 1)
                set line_start (+ i 1)
            } else {}
            set i (+ i 1)
        } else {
            /* Skip line comments */
            if (== c 35) {  /* '#' */
                while (and (< i source_len) (!= (char_at source i) 10)) {
                    set i (+ i 1)
                }
            } else {
                /* Handle tokens */
                let column: int = (+ (- i line_start) 1)
                
                /* String literals */
                if (== c 34) {  /* '"' */
                    set i (+ i 1)
                    let start: int = i
                    while (and (< i source_len) (!= (char_at source i) 34)) {
                        if (and (== (char_at source i) 92) (< (+ i 1) source_len)) {
                            set i (+ i 2)
                        } else {
                            set i (+ i 1)
                        }
                    }
                    let str_val: string = (substr source start (- i start))
                    /* array_push equivalent - not implemented yet, skip for now */
                    set i (+ i 1)
                    set token_count (+ token_count 1)
                } else {
                    /* Numbers */
                    if (or (char_is_digit c) 
                          (and (== c 45) (and (< (+ i 1) source_len) 
                                               (char_is_digit (char_at source (+ i 1)))))) {
                        let start: int = i
                        if (== c 45) { set i (+ i 1) } else {}
                        
                        while (and (< i source_len) (char_is_digit (char_at source i))) {
                            set i (+ i 1)
                        }
                        
                        /* Check for float */
                        if (and (< i source_len) 
                               (and (== (char_at source i) 46)
                                    (and (< (+ i 1) source_len) 
                                         (char_is_digit (char_at source (+ i 1)))))) {
                            set i (+ i 1)
                            while (and (< i source_len) (char_is_digit (char_at source i))) {
                                set i (+ i 1)
                            }
                        } else {}
                        set token_count (+ token_count 1)
                    } else {
                        /* Identifiers and keywords */
                        if (char_can_start_id c) {
                            let start: int = i
                            while (and (< i source_len) (char_can_continue_id (char_at source i))) {
                                set i (+ i 1)
                            }
                            set token_count (+ token_count 1)
                        } else {
                            /* Operators and punctuation - skip for now */
                            set i (+ i 1)
                            set token_count (+ token_count 1)
                        }
                    }
                }
            }
        }
    }
    
    /* For now, return an empty array - full implementation needs dynamic arrays */
    return tokens
}

shadow lex {
    let source: string = "fn add() {}"
    let tokens: array<Token> = (lex source)
    /* Just check it doesn't crash */
    assert (== 1 1)
}

/* Simple test */
fn test_lexer_basics() -> int {
    let source: string = "fn"
    let tokens: array<Token> = (lex source)
    return 0
}

shadow test_lexer_basics {
    assert (== (test_lexer_basics) 0)
}

fn main() -> int {
    (println "Nanolang Self-Hosted Lexer V2")
    (println "Status: Partially implemented - needs dynamic arrays")
    return 0
}

shadow main {
    assert (== (main) 0)
}

