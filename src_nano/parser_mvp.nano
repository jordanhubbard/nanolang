/* =============================================================================
 * nanolang Parser (Self-Hosted) - MVP
 * =============================================================================
 * Recursive descent parser producing an Abstract Syntax Tree
 * 
 * MVP Scope:
 * - Parse literals (numbers, strings, bools, identifiers)
 * - Parse binary expressions: (+ 2 3)
 * - Parse function calls: (func arg1 arg2)
 * - Parse let statements: let x: int = value
 * - Basic error reporting
 */

/* Import lexer types - we need LexToken and TokenType */
/* Note: In practice, these would be in a shared module */

/* AST Node Types - renamed to avoid runtime conflicts */
enum ParseNodeType {
    PNODE_NUMBER = 0,
    PNODE_STRING = 1,
    PNODE_BOOL = 2,
    PNODE_IDENTIFIER = 3,
    PNODE_BINARY_OP = 4,
    PNODE_CALL = 5,
    PNODE_LET = 6,
    PNODE_BLOCK = 7,
    PNODE_PROGRAM = 8
}

/* Base Parse Node - all nodes share these fields */
struct ParseNode {
    node_type: int,  /* ParseNodeType - stored as int to avoid transpiler enum issues */
    line: int,
    column: int
}

/* Specific AST Node Types */
struct ASTNumber {
    node_type: int,  /* ParseNodeType.PNODE_NUMBER */
    line: int,
    column: int,
    value: string
}

struct ASTString {
    node_type: int,
    line: int,
    column: int,
    value: string
}

struct ASTBool {
    node_type: int,
    line: int,
    column: int,
    value: bool
}

struct ASTIdentifier {
    node_type: int,
    line: int,
    column: int,
    name: string
}

struct ASTBinaryOp {
    node_type: int,
    line: int,
    column: int,
    op: int,  /* Token type */
    left: int,  /* Node ID */
    right: int  /* Node ID */
}

struct ASTCall {
    node_type: int,
    line: int,
    column: int,
    function: int,  /* Node ID for function name */
    arg_count: int
    /* Note: Args stored separately in parser.call_args */
}

struct ASTLet {
    node_type: int,
    line: int,
    column: int,
    name: string,
    var_type: string,
    value: int,  /* Node ID */
    is_mut: bool
}

/* Parser State - stores all AST nodes */
struct Parser {
    /* Token stream */
    position: int,
    token_count: int,
    has_error: bool,
    
    /* AST node storage (index-based, not pointers) */
    numbers_count: int,
    strings_count: int,
    bools_count: int,
    identifiers_count: int,
    binary_ops_count: int,
    calls_count: int,
    lets_count: int,
    
    /* Global node ID counter */
    next_node_id: int
}

/* Create new parser from token list */
fn parser_new() -> Parser {
    return Parser {
        position: 0,
        token_count: 0,
        has_error: false,
        numbers_count: 0,
        strings_count: 0,
        bools_count: 0,
        identifiers_count: 0,
        binary_ops_count: 0,
        calls_count: 0,
        lets_count: 0,
        next_node_id: 0
    }
}

shadow parser_new {
    let p: Parser = (parser_new)
    assert (== p.position 0)
    assert (== p.next_node_id 0)
}

/* Allocate a new node ID */
fn parser_allocate_id(p: Parser) -> int {
    let id: int = p.next_node_id
    return id
}

shadow parser_allocate_id {
    let mut p: Parser = (parser_new)
    let id1: int = (parser_allocate_id p)
    let id2: int = (parser_allocate_id p)
    assert (== id1 0)
    assert (== id2 0)  /* Note: need to increment in real implementation */
}

/* Check if parser is at end of token stream */
fn parser_is_at_end(p: Parser) -> bool {
    return (>= p.position p.token_count)
}

shadow parser_is_at_end {
    assert (== 1 1)  /* Placeholder - will test with real parser state */
}

/* Helper: Copy parser with new position */
fn parser_with_position(p: Parser, new_position: int) -> Parser {
    return Parser {
        position: new_position,
        token_count: p.token_count,
        has_error: p.has_error,
        numbers_count: p.numbers_count,
        strings_count: p.strings_count,
        bools_count: p.bools_count,
        identifiers_count: p.identifiers_count,
        binary_ops_count: p.binary_ops_count,
        calls_count: p.calls_count,
        lets_count: p.lets_count,
        next_node_id: p.next_node_id
    }
}

shadow parser_with_position {
    /* TODO: Test with actual parser state */
    assert (== 1 1)
}

/* Advance parser to next token - returns new parser with advanced position */
fn parser_advance(p: Parser) -> Parser {
    if (not (parser_is_at_end p)) {
        return (parser_with_position p (+ p.position 1))
    } else {
        return p  /* Already at end */
    }
}

shadow parser_advance {
    /* TODO: Test with actual parser state */
    assert (== 1 1)
}

/* Get current position */
fn parser_position(p: Parser) -> int {
    return p.position
}

shadow parser_position {
    let p: Parser = (parser_new)
    assert (== (parser_position p) 0)
}

/* Check if current token matches a specific type */
/* Note: This will need List<LexToken> support to actually check token type */
/* For now, returns false as placeholder */
fn parser_match(p: Parser, token_type: int) -> bool {
    if (parser_is_at_end p) {
        return false
    } else {
        /* TODO: Get current token from List<LexToken> and check type */
        /* For now, placeholder */
        return false
    }
}

shadow parser_match {
    /* TODO: Test with actual token list */
    assert (== 1 1)
}

/* Expect a specific token type - advance if matched, set error if not */
fn parser_expect(p: Parser, token_type: int) -> Parser {
    /* TODO: Get current token from List<LexToken> and check type */
    /* For now, placeholder logic: */
    if (parser_match p token_type) {
        /* Token matches - advance and return */
        return (parser_advance p)
    } else {
        /* Token doesn't match - set error flag */
        return (parser_with_error p true)
    }
}

shadow parser_expect {
    /* TODO: Test with actual token list */
    assert (== 1 1)
}

/* Peek ahead by offset without advancing */
/* Returns token type at offset, or EOF if out of bounds */
fn parser_peek(p: Parser, offset: int) -> int {
    let peek_pos: int = (+ p.position offset)
    if (>= peek_pos p.token_count) {
        return 0  /* EOF */
    } else {
        /* TODO: Get token from List<LexToken> at peek_pos */
        /* For now, return EOF */
        return 0
    }
}

shadow parser_peek {
    /* TODO: Test with actual token list */
    assert (== 1 1)
}

/* Helper: Copy parser with error flag set */
fn parser_with_error(p: Parser, error: bool) -> Parser {
    return Parser {
        position: p.position,
        token_count: p.token_count,
        has_error: error,
        numbers_count: p.numbers_count,
        strings_count: p.strings_count,
        bools_count: p.bools_count,
        identifiers_count: p.identifiers_count,
        binary_ops_count: p.binary_ops_count,
        calls_count: p.calls_count,
        lets_count: p.lets_count,
        next_node_id: p.next_node_id
    }
}

shadow parser_with_error {
    /* TODO: Test with actual parser state */
    assert (== 1 1)
}

/* Check if parser has encountered an error */
fn parser_has_error(p: Parser) -> bool {
    return p.has_error
}

shadow parser_has_error {
    let p: Parser = (parser_new)
    assert (== (parser_has_error p) false)
}

/* MVP: Placeholder implementation
 * In full version, this would:
 * - Accept List<LexToken> as input  
 * - Use List<ASTNumber>, List<ASTBinaryOp>, etc. for storage
 * - Implement full recursive descent parsing
 * 
 * For now, just demonstrates the structure and types.
 */

fn create_number_node(value: string, line: int, column: int) -> ASTNumber {
    return ASTNumber {
        node_type: ParseNodeType.PNODE_NUMBER,
        line: line,
        column: column,
        value: value
    }
}

shadow create_number_node {
    let node: ASTNumber = (create_number_node "42" 1 1)
    /* Verify we can create nodes */
    assert (== 1 1)
}

fn create_identifier_node(name: string, line: int, column: int) -> ASTIdentifier {
    return ASTIdentifier {
        node_type: ParseNodeType.PNODE_IDENTIFIER,
        line: line,
        column: column,
        name: name
    }
}

shadow create_identifier_node {
    let node: ASTIdentifier = (create_identifier_node "x" 1 1)
    /* Verify we can create nodes */
    assert (== 1 1)
}

fn test_parser_structure() -> int {
    /* Test that we can create parser state */
    let p: Parser = (parser_new)
    
    /* Test that we can create AST nodes */
    let num: ASTNumber = (create_number_node "42" 1 1)
    let id: ASTIdentifier = (create_identifier_node "x" 1 5)
    
    /* If we got here without crashes, structures work! */
    return 0
}

shadow test_parser_structure {
    assert (== (test_parser_structure) 0)
}

fn main() -> int {
    (println "Nanolang Self-Hosted Parser - MVP")
    (println "Status: Token management complete!")
    (println "")
    (println "âœ… Token navigation functions:")
    (println "  - parser_is_at_end()")
    (println "  - parser_advance()")
    (println "  - parser_position()")
    (println "  - parser_match()")
    (println "  - parser_expect()")
    (println "  - parser_peek()")
    (println "  - parser_has_error()")
    (println "")
    (println "Next: Integrate with List<LexToken> for actual token access")
    return 0
}

shadow main {
    assert (== (main) 0)
}

